{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOZpIdLrnLykNxkaozpBgNs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/junfrankohara/neutrophils_detection/blob/main/neutrophils_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M0Bw4HonfSN6",
        "outputId": "d3209801-1836-41cf-d3ca-33354d1adfff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33m\r0% [Working]\u001b[0m\r            \rHit:1 https://cloud.r-project.org/bin/linux/ubuntu focal-cran40/ InRelease\n",
            "Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  InRelease\n",
            "Hit:3 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal InRelease\n",
            "Get:4 http://security.ubuntu.com/ubuntu focal-security InRelease [114 kB]\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu focal InRelease\n",
            "Hit:6 http://ppa.launchpad.net/cran/libgit2/ubuntu focal InRelease\n",
            "Get:7 http://archive.ubuntu.com/ubuntu focal-updates InRelease [114 kB]\n",
            "Hit:8 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal InRelease\n",
            "Hit:9 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu focal InRelease\n",
            "Get:10 http://archive.ubuntu.com/ubuntu focal-backports InRelease [108 kB]\n",
            "Hit:11 http://ppa.launchpad.net/ubuntugis/ppa/ubuntu focal InRelease\n",
            "Fetched 336 kB in 2s (176 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "23 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "openslide-tools is already the newest version (3.4.1+dfsg-4).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 23 not upgraded.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: openslide-python in /usr/local/lib/python3.9/dist-packages (1.2.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.9/dist-packages (from openslide-python) (8.4.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: segmentation_models_pytorch==0.2.1 in /usr/local/lib/python3.9/dist-packages (0.2.1)\n",
            "Requirement already satisfied: torchvision>=0.5.0 in /usr/local/lib/python3.9/dist-packages (from segmentation_models_pytorch==0.2.1) (0.14.1+cu116)\n",
            "Requirement already satisfied: efficientnet-pytorch==0.6.3 in /usr/local/lib/python3.9/dist-packages (from segmentation_models_pytorch==0.2.1) (0.6.3)\n",
            "Requirement already satisfied: pretrainedmodels==0.7.4 in /usr/local/lib/python3.9/dist-packages (from segmentation_models_pytorch==0.2.1) (0.7.4)\n",
            "Requirement already satisfied: timm==0.4.12 in /usr/local/lib/python3.9/dist-packages (from segmentation_models_pytorch==0.2.1) (0.4.12)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.9/dist-packages (from efficientnet-pytorch==0.6.3->segmentation_models_pytorch==0.2.1) (1.13.1+cu116)\n",
            "Requirement already satisfied: munch in /usr/local/lib/python3.9/dist-packages (from pretrainedmodels==0.7.4->segmentation_models_pytorch==0.2.1) (2.5.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from pretrainedmodels==0.7.4->segmentation_models_pytorch==0.2.1) (4.65.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torchvision>=0.5.0->segmentation_models_pytorch==0.2.1) (4.5.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.9/dist-packages (from torchvision>=0.5.0->segmentation_models_pytorch==0.2.1) (8.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from torchvision>=0.5.0->segmentation_models_pytorch==0.2.1) (1.22.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from torchvision>=0.5.0->segmentation_models_pytorch==0.2.1) (2.27.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from munch->pretrainedmodels==0.7.4->segmentation_models_pytorch==0.2.1) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision>=0.5.0->segmentation_models_pytorch==0.2.1) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision>=0.5.0->segmentation_models_pytorch==0.2.1) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision>=0.5.0->segmentation_models_pytorch==0.2.1) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision>=0.5.0->segmentation_models_pytorch==0.2.1) (2022.12.7)\n",
            "fatal: destination path 'yolov5' already exists and is not an empty directory.\n",
            "/content/yolov5\n"
          ]
        }
      ],
      "source": [
        "!apt update && apt install -y openslide-tools\n",
        "!pip install openslide-python\n",
        "!pip install segmentation_models_pytorch==0.2.1\n",
        "!git clone https://github.com/ultralytics/yolov5\n",
        "%cd /content/yolov5/\n",
        "!pip install -qr requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import openslide\n",
        "import segmentation_models_pytorch as smp\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "import skimage.io\n",
        "from skimage.transform import rescale, resize"
      ],
      "metadata": {
        "id": "vS5ecoaXgH-b"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# WSIãƒ•ã‚¡ã‚¤ãƒ«ã¨ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã®ãƒã‚¦ãƒ³ãƒˆ\n",
        "%cd /content/\n",
        "import gdown\n",
        "url = \"https://drive.google.com/drive/folders/1C8UksO10b5BB6axEoo-0ABQs0RL4p7pc?usp=share_link\"\n",
        "gdown.download_folder(url, quiet = True, use_cookies= False, )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aJN5LLOVgYxu",
        "outputId": "a232113e-c85a-4535-e95a-229de17528f0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/demo/best.pt',\n",
              " '/content/demo/sample.ndpi',\n",
              " '/content/demo/seg_model.pth']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰\n",
        "ENCODER = \"efficientnet-b4\"\n",
        "ENCODER_WEIGHTS = \"imagenet\"\n",
        "preprocessing_fn = smp.encoders.get_preprocessing_fn(ENCODER, ENCODER_WEIGHTS)\n",
        "DEVICE = \"cuda\"\n",
        "seg_model = torch.load('/content/demo/seg_model.pth')\n",
        "\n",
        "%cd /content/yolov5/\n",
        "# å¥½ä¸­çƒæ¤œå‡ºãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰ã¨é–¾å€¤ã®è¨­å®š\n",
        "neu_model = torch.hub.load(\"\", \"custom\", path='/content/demo/best.pt', source=\"local\")\n",
        "neu_model.conf = 0.5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ojGAtmzGggGP",
        "outputId": "fc6b1470-b043-472c-cbb5-babdfdda09ce"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "YOLOv5 ğŸš€ v7.0-128-gb96f35c Python-3.9.16 torch-1.13.1+cu116 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/yolov5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fusing layers... \n",
            "YOLOv5l summary: 367 layers, 46113663 parameters, 0 gradients\n",
            "Adding AutoShape... \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# openslide ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é–‹ã\n",
        "%cd /\n",
        "\n",
        "wsi = '/content/demo/sample.ndpi'\n",
        "slide = openslide.open_slide(wsi)\n",
        "shapes=list(slide.level_dimensions)\n",
        "level5=slide.read_region((0,0), 5, shapes[5])\n",
        "image = np.array(level5)\n",
        "image=image[:,:,0:3]\n",
        "small_img = np.array(image)\n",
        "plt.imshow(small_img)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yN96kPGGi-LB",
        "outputId": "f7f1e50d-9c1c-4cb1-eb1b-cd92756ea93a"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f0961573490>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# openCVã®è¼ªéƒ­æ¤œå‡ºæ©Ÿèƒ½ã‚’ä½¿ã£ã¦ç”Ÿæ¤œéƒ¨ä½ã®ROIã‚’è¨­å®šã™ã‚‹\n",
        "\n",
        "#è¼ªéƒ­æ¤œå‡ºã®ãŸã‚ã«ï¼’å€¤åŒ–\n",
        "im_gray = cv2.cvtColor(small_img, cv2.COLOR_BGR2GRAY)\n",
        "ret2,th2 = cv2.threshold(im_gray,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
        "#01å¤‰æ›\n",
        "th2[th2==0]=1\n",
        "th2[th2==255]=0\n",
        "\n",
        "# è¼ªéƒ­ã‚’æŠ½å‡ºã™ã‚‹ã€‚\n",
        "contours, hierarchy = cv2.findContours(\n",
        "    th2, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE\n",
        ")\n",
        "\n",
        "# æ¤œå‡ºã•ã‚ŒãŸé ˜åŸŸã‚’rectangleã§æå†™\n",
        "area_num = 5000\n",
        "contours_filtered = list(filter(lambda x: cv2.contourArea(x) > area_num, contours))\n",
        "\n",
        "for i in contours_filtered:\n",
        "    x,y,width,height = cv2.boundingRect(i)\n",
        "    cv2.rectangle(small_img, (x,y),(x+width, y+height), color = (0,255,0), thickness =2 )\n",
        "plt.imshow(small_img)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fo-Vvizpj7ls",
        "outputId": "e159dcf0-f77d-42c5-a881-e8f40e67e1a7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f09e3328910>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ã¾ãšã²ã¨ã¤ç›®ã®æ¤œä½“ã‚’ãƒ¬ãƒ™ãƒ«1ã§ã¨ã‚Šã ã™\n",
        "bx=0\n",
        "\n",
        "#æ¤œå‡ºã—ãŸæ¤œä½“ã‚’å›²ã£ãŸçŸ©å½¢ã®åº§æ¨™ãƒªã‚¹ãƒˆã‚’ä½œã‚‹\n",
        "specimen=[]\n",
        "for i in contours_filtered:\n",
        "    x,y,width,height = cv2.boundingRect(i)\n",
        "    specimen.append([x,y,width,height ])\n",
        "\n",
        "#æ¤œå‡ºã•ã‚ŒãŸç”Ÿæ¤œæ¤œä½“ã‚’å·¦ã‹ã‚‰é †ç•ªã«ä¸¦ã¹ç›´ã™\n",
        "specimen=sorted(specimen) \n",
        "position=specimen[bx]\n",
        "sp1=slide.read_region((position[0]*32, position[1]*32), 1, (position[2]*16,position[3]*16))\n",
        "sp1_array = np.array(sp1)\n",
        "sp1_array=np.array(sp1_array[:,:,0:3])\n",
        "print(sp1_array.shape)\n",
        "plt.imshow(sp1_array)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qYfniP2kkLAg",
        "outputId": "821a5ba6-0ec1-4926-d9ed-569f8b49a848"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3424, 3232, 3)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f09e34863a0>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#ä¸Šçš®ã®ãƒã‚¹ã‚¯ã‚’ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³\n",
        "#é©å¿œã•ã›ã‚‹ã¾ãˆã«ç¸¦æ¨ªã¨ã‚‚ã«640ã§å‰²ã‚Šåˆ‡ã‚Œã‚‹ã‚ˆã†ã«np.zerosã®è¡Œåˆ—ã‚’åŠ ãˆã¦æ•´ãˆã‚‹\n",
        "\n",
        "\n",
        "\n",
        "def crop_to_640pix(img):\n",
        "    crop_array=img.reshape(int(img.shape[0]/640),640,int((img.shape[1])/640),640, 3)\n",
        "    crop_array=crop_array.transpose([0,2,1,3,4])\n",
        "    crop_array=crop_array.reshape(-1,640,640,3)\n",
        "    return crop_array\n",
        "\n",
        "def assemble_with640pix(crop_arrays, img_height, img_width):\n",
        "    re_x=crop_arrays.reshape(int(img_height/640),int(img_width/640),640,640)\n",
        "    re_x=re_x.transpose([0,2,1,3])\n",
        "    return re_x.reshape(img_height, img_width).astype(\"uint8\")\n",
        "\n",
        "img=sp1_array\n",
        "tile_size=640\n",
        "add_space1=np.zeros((img.shape[0], tile_size-img.shape[1]%tile_size, 3))\n",
        "img=np.hstack((img, add_space1)).astype(\"uint8\")\n",
        "add_space2=np.zeros((tile_size-img.shape[0]%tile_size, img.shape[1], 3))\n",
        "img=np.vstack((img, add_space2)).astype(\"uint8\")\n",
        "print(img.shape)\n",
        "\n",
        "#ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³\n",
        "crop_array=crop_to_640pix(img)\n",
        "\n",
        "epi_list=[]\n",
        "for rgb in tqdm(crop_array):\n",
        "    half_rgb=resize(rgb, (320, 320), anti_aliasing=True)\n",
        "    image = preprocessing_fn(half_rgb)\n",
        "    image = image.transpose(2, 0, 1).astype('float32')\n",
        "    image=torch.from_numpy(image).to(DEVICE).unsqueeze(0)\n",
        "    predict = seg_model(image)\n",
        "    predict = predict.detach().cpu().numpy()[0]\n",
        "    pr_epithelium=predict[3,:,:]\n",
        "    pr_epithelium = np.where(pr_epithelium>0.7, 1, 0)\n",
        "    pr_epithelium=pr_epithelium.repeat(2, axis=0).repeat(2, axis=1)\n",
        "    epi_list.append(pr_epithelium)\n",
        "epi_arrays=np.stack(epi_list)\n",
        "epi_arrays.shape\n",
        "detect_epi=assemble_with640pix(epi_arrays, img.shape[0], img.shape[1])\n",
        "#ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³çµæœã®è¡¨ç¤º\n",
        "plt.imshow(detect_epi)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pcj22jK4pT5b",
        "outputId": "27685ddc-71ab-4cc9-8dbf-8b005b6ce182"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3840, 3840, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:04<00:00,  8.28it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f09e34aa8b0>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def crop_to_tile(img, tile_size):\n",
        "    img=img[:int(img.shape[0]/tile_size)*tile_size, :int(img.shape[1]/tile_size)*tile_size]\n",
        "    crop_array=img.reshape(int(img.shape[0]/tile_size),tile_size,int((img.shape[1])/tile_size),tile_size)\n",
        "    crop_array=crop_array.transpose([0,2,1,3])\n",
        "    crop_array=crop_array.reshape(-1,tile_size,tile_size)\n",
        "    return crop_array\n",
        "\n",
        "bai=32\n",
        "\n",
        "epi_masks=crop_to_tile(detect_epi, 160)\n",
        "neurophils=0\n",
        "\n",
        "for i in tqdm(range(len(epi_masks))):\n",
        "  if epi_masks[i].sum() > 100:\n",
        "    # é–“è³ªæˆåˆ†ã¨ä¸Šçš®æˆåˆ†ãŒå­˜åœ¨ã™ã‚‹levl0ç›¸å½“ã®320pixã®ã‚¿ã‚¤ãƒ«ã‚’å–ã‚Šå‡ºã™\n",
        "    width_bin=int(i%(detect_epi.shape[1]/160))\n",
        "    height_bin=int(i//(detect_epi.shape[1]/160))\n",
        "    crop_position=(int(position[1]*bai)+width_bin*320, int(position[2]*bai+height_bin*320))\n",
        "    img = slide.read_region((crop_position), 0, (320,320))\n",
        "    img_array = np.array(img)\n",
        "    img_array=np.array(img_array[:,:,0:3])\n",
        "    # ä¸Šçš®ãƒã‚¹ã‚¯ãƒ‡ãƒ¼ã‚¿ã‚’ä½œã‚‹\n",
        "    epi_mask=cv2.resize(epi_masks[i], (320, 320))\n",
        "    epi_tile = img_array*np.stack([epi_mask, epi_mask, epi_mask], axis=-1)\n",
        "    # ä¸Šçš®å†…ã®å¥½ä¸­çƒæ¤œå‡º\n",
        "    neu_result = neu_model(epi_tile)\n",
        "    neu_bb= neu_result.xyxy[0].to('cpu').detach().numpy().copy()\n",
        "    # å¥½ä¸­çƒæ•°ã®ã‚«ã‚¦ãƒ³ãƒˆ\n",
        "    neurophils= neurophils + (len(neu_bb))\n",
        "\n",
        "print(\"å¥½ä¸­çƒæ•°ï¼š\"+ str(neurophils) + \"å€‹\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TFL7sgh5qCLc",
        "outputId": "adb60776-a1e2-4142-be6b-b2633ae01c4e"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [00:10<00:00, 56.79it/s] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "å¥½ä¸­çƒæ•°ï¼š105å€‹\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# æ¬¡ã«2ã¤ç›®ã‚’ã‚«ã‚¦ãƒ³ãƒˆã—ã¦ã¿ã‚‹\n",
        "bx=1\n",
        "pre_list=[]\n",
        "\n",
        "position=specimen[bx]\n",
        "sp1=slide.read_region((position[0]*32, position[1]*32), 1, (position[2]*16,position[3]*16))\n",
        "sp1_array = np.array(sp1)\n",
        "sp1_array=np.array(sp1_array[:,:,0:3])\n",
        "img=sp1_array\n",
        "tile_size=640\n",
        "add_space1=np.zeros((img.shape[0], tile_size-img.shape[1]%tile_size, 3))\n",
        "img=np.hstack((img, add_space1)).astype(\"uint8\")\n",
        "add_space2=np.zeros((tile_size-img.shape[0]%tile_size, img.shape[1], 3))\n",
        "img=np.vstack((img, add_space2)).astype(\"uint8\")\n",
        "\n",
        "#ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³\n",
        "crop_array=crop_to_640pix(img)\n",
        "\n",
        "epi_list=[]\n",
        "print(\"ä¸Šçš®ã®ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³â€¦\")\n",
        "for rgb in tqdm(crop_array):\n",
        "    half_rgb=resize(rgb, (320, 320), anti_aliasing=True)\n",
        "    image = preprocessing_fn(half_rgb)\n",
        "    image = image.transpose(2, 0, 1).astype('float32')\n",
        "    image=torch.from_numpy(image).to(DEVICE).unsqueeze(0)\n",
        "    predict = seg_model(image)\n",
        "    predict = predict.detach().cpu().numpy()[0]\n",
        "    pr_epithelium=predict[3,:,:]\n",
        "    pr_epithelium = np.where(pr_epithelium>0.7, 1, 0)\n",
        "    pr_epithelium=pr_epithelium.repeat(2, axis=0).repeat(2, axis=1)\n",
        "    epi_list.append(pr_epithelium)\n",
        "epi_arrays=np.stack(epi_list)\n",
        "detect_epi=assemble_with640pix(epi_arrays, img.shape[0], img.shape[1])\n",
        "#ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³çµæœã®è¡¨ç¤º\n",
        "plt.imshow(detect_epi)\n",
        "epi_masks=crop_to_tile(detect_epi, 160)\n",
        "neurophils=0\n",
        "print(\"å¥½ä¸­çƒã‚’è¨ˆæ¸¬â€¦\")\n",
        "for i in tqdm(range(len(epi_masks))):\n",
        "  if epi_masks[i].sum() > 100:\n",
        "    # ä¸Šçš®æˆåˆ†ãŒå­˜åœ¨ã™ã‚‹levl0ç›¸å½“ã®320pixã®ã‚¿ã‚¤ãƒ«ã‚’å–ã‚Šå‡ºã™\n",
        "    width_bin=int(i%(detect_epi.shape[1]/160))\n",
        "    height_bin=int(i//(detect_epi.shape[1]/160))\n",
        "    crop_position=(int(position[0]*bai)+width_bin*320, int(position[1]*bai+height_bin*320))\n",
        "    img = slide.read_region((crop_position), 0, (320,320))\n",
        "    img_array = np.array(img)\n",
        "    img_array=np.array(img_array[:,:,0:3])\n",
        "    # ä¸Šçš®ãƒã‚¹ã‚¯ãƒ‡ãƒ¼ã‚¿ã‚’ä½œã‚‹\n",
        "    epi_mask=cv2.resize(epi_masks[i], (320, 320))\n",
        "    epi_tile = img_array*np.stack([epi_mask, epi_mask, epi_mask], axis=-1)\n",
        "    # ä¸Šçš®å†…ã®å¥½ä¸­çƒæ¤œå‡º\n",
        "    neu_result = neu_model(epi_tile)\n",
        "    neu_bb= neu_result.xyxy[0].to('cpu').detach().numpy().copy()\n",
        "    # å¥½ä¸­çƒæ•°ã®ã‚«ã‚¦ãƒ³ãƒˆ\n",
        "    neurophils= neurophils + (len(neu_bb))\n",
        "    #è¦‹ã¤ã‘ãŸå¥½ä¸­çƒã‚’ç¤ºã—ãŸç”»åƒã‚’ãƒªã‚¹ãƒˆã«å…¥ã‚Œã‚‹\n",
        "    if len(neu_bb) > 0:\n",
        "      for box in range(len(neu_bb)):\n",
        "        cv2.rectangle(epi_tile,(int(neu_bb[box][0]), int(neu_bb[box][1])),(int(neu_bb[box][2]),int(neu_bb[box][3])), (255,0,0) , thickness=2)\n",
        "      pre_list.append(epi_tile)\n",
        "print(\"å¥½ä¸­çƒæ•°ï¼š\"+ str(neurophils) + \"å€‹\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hTgEow0NqUxb",
        "outputId": "d9fc6abf-b84e-455a-dc8b-c627581b7325"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ä¸Šçš®ã®ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³â€¦\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:04<00:00,  7.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "å¥½ä¸­çƒã‚’è¨ˆæ¸¬â€¦\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 480/480 [00:05<00:00, 93.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "å¥½ä¸­çƒæ•°ï¼š6å€‹\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# æ¤œå‡ºã—ãŸå¥½ä¸­çƒã‚’ç¢ºèª\n",
        "plt.rcParams['figure.figsize'] = (20.0, 20.0)\n",
        "fig, axes = plt.subplots(nrows=4, ncols=2)\n",
        "for j in range(8):\n",
        "    axes[j//2, j%2].imshow(pre_list[j])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "id": "O94FggD4qn5Z",
        "outputId": "6da2f836-63d4-4b35-c352-edc456b7cd48"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-85effb5b9550>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mncols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpre_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ]
    }
  ]
}